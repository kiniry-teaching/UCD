Revision:
0.1	EB	First draft

Title:	Kinephon
Team:	Intuitive Aptitudes
Members:	Eva Darulova	05817625
			Sumbo Ajisafe	05005451
			David Swords	05477689
			Eliott Bartley	05806500
			Jakub Dostal	05844151

Project Parts:
Installer <Dave>
This installer could come in different flavours, depending on how the project comes along.
The two main options are one for Linux and one for Windows.
Linux:
	This will be a .deb (Debian) package. Itself can come in two flavours which are binary and
	source. A binary package contains all the executables, man pages etc. and are unpacked using
	the Debian utility dpkg. A source package contains a .dsc file describing the source package itself,
	a orig.tar.gz containing the orignal source code and a diff.gz describing the Debian specfic changes
	to the source. The dpkg-source, packs and unpacks the Debian source archives.
Windows:
	#TO DO - Have to do a little bit more research. Signed Dave

Configuration
<jakub>

Interface
<dave, jakub>
	#TO DO - We can chat about the nuts and bolts of this in the meeting tomorrow. Signed Dave

Camera
<jakub>

Connection to Computer
<jakub>

Parser
<dave>

Recorder
Keeps a history of data from the Parser. Each blob tracked by the Camera will be have its own history and be uniquely identifiable. This part of the project will be broken into the following classes
Frame
Holds information about a single blob and a single point in time. This will include blob position, vector to next position, frame time, and a tag. Tag will be modifiable by the Analyser and allow the Analyser to attach a custom data structure to the frame during processing. If not saved elsewhere, this tag will be deleted along with the frame.
Animation
Holds a list of Frames for a single tracked blob. Responsible for adding and removing frames for its blob
Recorder
Holds a list of animations, one for each tracked blob. Responsible for communicating with the parser and analyser, passing data for each frame on to the correct Animation blob and giving requested Animations to the Analyser

Analyser
Analyses a blob's animation to calculate speed, acceleration, shape, position, size and angle. Speed, acceleration, and shape will be determined by graphing each ones' properties against a large grid and comparing it to preset approximations of known movements. Position will be taken by splitting the camera area into a small grid and picking one cell as the movements position, biased towards the first and centre points in the movement. As all movements will be given in vector data, the movement will first be scaled during graphing to determined shape, and size will then be the amount by which it had to be scaled. However, If a shape cannot be determined, size will be meaningless. Angle will also require that a shape is known, the shape will be rotated to fit it to known shapes and the closest match will determine the angle. i.e. a diamond shape would be picked before a square at 45 degrees.
Speed, acceleration, and shape will be found by comparing to predefined shapes, which will be described as a weight of the areas a shape would pass through. This weight will be in the range (0..1) where 1 are areas that will be crossed, and 0 are areas that are not crossed. The movement is then rendered on top of this using some rasterisation algorithm (Bresnham's for example) and the weight of the points crossed by the rasterisation will be totalled and divided by the number of points crossed giving a normal weight. (See shape.png; green is predetermined shape positions, red is recorded positions/vectors, and blue is the rasterisation of the movement. The green covered by blue calculates the weight that this movement makes this shape). The shape with a high enough normal weight will be picked and if several shapes are acceptable, the highest will be chosen. In addition to the weights, each predefined shape will also contain areas that must be crossed, the order they should be crossed, and the sides the area should be entered and exited. This will allow movements that don't complete a shape to be ignored, winding order to be determined, as well as differentiate between a movement that would follow an 8 shape or two 3's back to back. This method can also be used with speed or acceleration, plotted against time, and rendered on predetermined graphs, which could be used to determine the tempo, style, etc. i.e. same shape, with different acceleration spikes could mean same melody, different rhythm, or something?
The analyser will be broken into the following classes
Shape
Stores each predetermined shape. Given an animation, will return the weight of how close the movement matches the shape along with angle and scale information if a match was found. A shape can contain speed and acceleration sub-shapes, which the closest match will also be retuned if a match was found. Each shape will specify whether its purpose is to match movements, speeds, or accelerations.
Shapes
Container of all known predetermined shapes. Given an animation, will return a list of shapes, ordered by closest match, along with its closest matching speed, acceleration sub-shapes. The list will be limited to shapes that are matched within a given range. Analyser can use this information to decide not to use a high matching shape if it looks like a lower matching shape will be used in the future that better suites the flow of the musicâ€¦ Is this making it too complicated? Need to put more thought into this but it could also be set to watch speed and give a shape a little more weight if it looks like an incomplete shape will become complete given a little more time. There will have to be something to differentiate between a line shape and every other shape that is made up of lines, a way to determine when a movement is complete[?]
Analyser
Gets the latest animation from the Recorder and passes it on to Shapes. If no shape is found, speed and acceleration tests will be done independent of shape. Final nearest matching shape will be passed on to Interpreter. When a shape has been determined, the point up to where the shape was matched will be marked for deletion and everything before that point will be removed by the Recorder next time it runs

Interpreter
Will keep a short history of shapes and can either link a group of shapes to determine what sounds or music to play, or can take individual shapes to make a control switch. As shapes are used, they are deleted from the history. Don't have a clue how to make music with this, so don't know what classes will be needed[?]

Synthesis
<eva>

Generation
<eva>

Sound Recorder
<eva>

Visualisation
<dave>

Visual Recorder
Movement Recorder
Web app
<do secondary's need to be filled>

Dictionary:
Blob : Single IR light or reflective IR tape picked up by the Camera as an (X, Y) co-ordinate and radius