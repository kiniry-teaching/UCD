Revision:
0.1  DS  First draft
0.2  EB  Added fluff as possible direction to take proposal[?]
0.3  ED  Edited proposal as to how I would write it...
0.4  DS  Spelling and wording change
0.5  EB  Formatting and comments
0.6  DS	 Formatting, spelling and wording. Removed comments and included suggestions.
0.7  JD  Role definition, spellchecking...  
0.8  ED  sound role filled in
0.9  JD  Sound role beefing up (Eva, it's up to you if you agree with this.)

Title: Kinephon
Team: Intuitive Aptitudes
Members: 	Sumbo Ajisafe  05005451
      		David Swords   05477689
      		Eliott Bartley 05806500
      		Jakub Dostal   05844151
      		Eva Darulova   05817625

Introduction:
	In the creation of dance music, a musician has numerous theories, techniques,
instruments, and hardware and software to avail of. Music created in this
manner appears to entice people into dance. However, dance does not have to be
the response to music, nor music a product of impassive instruments; it may
well be the other way round: music should be the manifestation of dance. This
project aims to show that one does not have to follow the old paths. With the
help of software and IR cameras it will follow the users movements and produce
music that is not stifled by any boundaries arising by having the music first.

Overview:
	Kinephon will be a tool designed to realise movement as a audio composition.
This will be achieved by having the user wear or reflect IR lights. These IR
lights will be tracked by an IR camera (e.g. a Wiimote) and spatial informati
on will be transmitted to a Bluetooth enabled device for interpretation. The 
Kinephon software will use this data to build an animation of the movement 
and map those movements to audible samples, synths, or effects, thereby 
producing the movement's song. To enhance the use of the tool, the created data can be recorded, so that one 
can review and compare it later, maybe to the audio samples of other users.
    Code for a Wiimote interface is already available as OpenSource, but it may
be necessary that this is written from scratch in order to support variations
on functionality and platform independence. However, in relation to sound 
libraries, OpenSource ones will be used. Suitable APIs will have to be developed
between the different components to make the tool extendable and adaptable for
the future.
    These APIs will also make the project more manageable so that the work can be split. A substantial 
part of the project is to design a mapping between the user's movements and 
the music created that is natural and intuitive, easy to learn but at the same 
time one that leaves enough room for individuality.
     In order to appeal to the other senses as well and make the experience more
complete, optional features of this project include a graphical representation
of the music just created. This should be done in a symbolic way; the more 
harmonic the music, the more harmonic the graphical representation will be, thus
giving direct feedback to the user. Plus, with the immense popularity of social
networking sites a second optional feature could be a website. This could allow
users to upload, share and comment on the songs they created.

Requirements:
The project must...
    - produce a tool that is able to detect gestures and send the data in an appropriate format to the computer;
    - and be able to control the generation of sound though the combination of gestures supplied by the IR camera.
    - Also, it must record analysed data.
    - Moreover, it must include a simple GUI and audio visualisation providing 
      feedback and visual cues to the user.

Secondary requirements include...
    - a more complex graphical representation of the music created and more helpful feedback for
    the user.
    - a web service for sharing of creations.
    - preprocessed output from recordings for an attractive presentation.

Things that are not goals of the project include...
    - programming a sound library from scratch.
    - a complex interface in which the dancer can produce deterministic songs.
    - a tracker, sample editor, or direct manual music creator.

Technology:
    - IR camera e.g. Nintendo Wiimote or Webcam.
    - Bluetooth if Wiimote is used.
    - C++
    - XML
    - web technologies (generality due to the website being a secondary requirement)

Roles:
	Primary requirements:
		Hardware:
			Interface Design (David Swords, Jakub Dostal): Design an interface which will 
				allow the tool to gather as much information as possible about the user's
				movements while providing a continuous and reliable stream of information. 
			Data transfer 1 (Jakub Dostal): Develop a mechanism that will establish 
				the connection and manage all communication with the wiimote, providing all
				the necessary data for parsing (Primarily for linux and, if time permits, for 
				Windows as well).
			Data transfer 2 (David Swords): Parse the received data into meaningful information
				and design an API, which will allow the information to be collected for analysis.
		Software:
			Movement analysis and interpretation (Eliott Bartley, Sumbo Ajisafe):
				information analysis:  [to be filled]
				movement interpreter: [to be filled]
			Sound creation (Eva Darulova): 
			    Synthesis: Design an API that will take in higher-level information from the 
			        movement interpreter and map it onto audio characteristics such as (overlaid) 
			        frequency or power [, thus composing the music and creating a representation of 
			        the different elements that will characterise it.]
			    Generation: Using available sound libraries as reference, reliably create the sound
			        [using the information about its characteristics from the synthesis system]
			        (primary for Linux, if time permits for Windows as well).
			        
		Small parts:
			GUI (Jakub Dostal): Simple GUI that will help the user to connect and setup the wiimote,
				and prepare the system. 
			Installation system (David Swords): Create the deployment system (primarily for linux and,
				if time permits, for Windows) that will allow the user to easily install the tool.
			Primitive visualisation (David Swords): Aesthetically simple visual representation of 
				the created audio, providing the user with feedback and visual cues.
				
	Secondary requirements: [details to be added]
		Note: Specific people will be assigned to these as time and resources permit.
		Website:
			Graphical design
			Server-side back-end (for sharing and multimedia delivery)
			Social networking aspect
		Visualisation:
			More complex music representation and user feedback
			Flash/Silverlight (embeddable and online-usable anyway) audio/video production system